{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Camera Calibration with OpenCV\n",
    "===\n",
    "\n",
    "### The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the camera calibration matrix and distortion coefficients given a set of chessboard images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calibrate a camera, using a number of sample chessboard images\n",
    "# Save the resulting 'dist' and 'mtx' values in a pickle file named\n",
    "# 'calibration.p'\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import pickle\n",
    "%matplotlib inline\n",
    "\n",
    "def calibrate_camera():\n",
    "    \n",
    "    nx = 9\n",
    "    ny = 6\n",
    "\n",
    "    # prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(nx-1,ny-1,0)\n",
    "    objp = np.zeros((ny*nx,3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:nx, 0:ny].T.reshape(-1,2)\n",
    "\n",
    "    # Arrays to store object points and image points from all the images.\n",
    "    objpoints = [] # 3d points in real world space\n",
    "    imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "    # Make a list of calibration images\n",
    "    images = glob.glob(\"./camera_cal/calibration*.jpg\")\n",
    "\n",
    "    # Step through the list and search for chessboard corners\n",
    "    for idx, fname in enumerate(images):\n",
    "        img = cv2.imread(fname)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Find the chessboard corners\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (nx,ny), None)\n",
    "\n",
    "        # If found, add object points, image points\n",
    "        if ret == True:\n",
    "            sys.stdout.write('+')\n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners)\n",
    "        else:\n",
    "            sys.stdout.write('-')\n",
    "        \n",
    "    # Test undistortion on an image\n",
    "    img = cv2.imread('./camera_cal/calibration3.jpg')\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "\n",
    "    # Do camera calibration given object points and image points\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size, None, None)\n",
    "\n",
    "    # Save the camera calibration result for later use (we won't worry about rvecs / tvecs)\n",
    "    dist_pickle = {}\n",
    "    dist_pickle[\"mtx\"] = mtx\n",
    "    dist_pickle[\"dist\"] = dist\n",
    "    pickle.dump( dist_pickle, open( \"./calibration.p\", \"wb\" ) )\n",
    "    \n",
    "    return mtx, dist, img_size\n",
    "\n",
    "# Using chessboard patterns, calibrate camera\n",
    "mtx, dist, img_size = calibrate_camera()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display a sample chessboard calibration patter, alongside its undistorted transform\n",
    "\n",
    "Step through a list of checkerboard patterns and display the original alongside the undistorated transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import pickle\n",
    "%matplotlib inline\n",
    "\n",
    "output_images_dir = \"./output_images/\"\n",
    "\n",
    "def test_undist_patterns(mtx, dist, firstOnly=False, outputFile=False):\n",
    "\n",
    "    try:\n",
    "        os.mkdir(output_images_dir)\n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "    # Step through the list and undistort each image\n",
    "    for fname in sorted(glob.glob(os.path.join('./camera_cal/', 'calibration*.jpg'))):\n",
    "        img = cv2.imread(fname)\n",
    "\n",
    "        # Apply anti-distortion transforms to the image\n",
    "        dst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "\n",
    "        # Visualize undistortion\n",
    "        f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "        ax1.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        ax1.set_title('Original Image', fontsize=30)\n",
    "        ax2.imshow(cv2.cvtColor(dst, cv2.COLOR_BGR2RGB))\n",
    "        ax2.set_title('Undistorted Image', fontsize=30)\n",
    "        \n",
    "        if outputFile:\n",
    "            # Write each undistorted image to the 'output_images' dir\n",
    "            cv2.imwrite(output_images_dir + 'undist_' + fname[11:], dst)\n",
    "        \n",
    "        if firstOnly:\n",
    "            break\n",
    "            \n",
    "# Display undistorated checkerboard patterns\n",
    "test_undist_patterns(mtx, dist, firstOnly=True, outputFile=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply a distortion correction to (raw) test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path\n",
    "%matplotlib inline\n",
    "\n",
    "undist_images_dir = \"./undist_images/\"\n",
    "\n",
    "def undistort_test_images(mtx, dist):\n",
    "    \n",
    "    # Make a list of calibration images\n",
    "    test_images_dir = \"./test_images/\"\n",
    "\n",
    "    try:\n",
    "        os.mkdir(undist_images_dir)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Step through the list and undistort each image\n",
    "    for fname in sorted(glob.glob(os.path.join(test_images_dir, '*.jpg'))):\n",
    "        img = cv2.imread(fname)\n",
    "\n",
    "        # Apply anti-distortion transforms to the image\n",
    "        dst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "\n",
    "        # Write each undistorted image to the 'output_images' dir\n",
    "        cv2.imwrite(undist_images_dir + fname[14:], dst)\n",
    "\n",
    "        # Visualize undistortion\n",
    "        f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "        ax1.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        ax1.set_title('Original Image', fontsize=30)\n",
    "        ax2.imshow(cv2.cvtColor(dst, cv2.COLOR_BGR2RGB))\n",
    "        ax2.set_title('Undistorted Image', fontsize=30)        \n",
    "            \n",
    "    return output_images_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show test output\n",
    "Show sample transformations that demonstrate how we calibrated the camera to remove distorion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Using test_images, derive M and Minv for perspective transforms\n",
    "undistort_test_images(mtx, dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply color transforms, gradients, etc., to create a thresholded binary image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os.path\n",
    "%matplotlib inline\n",
    "    \n",
    "# Filter out the areas of the image where we don't expect to find\n",
    "# lane lines    \n",
    "def apply_trapezoid_mask(image, ignore_mask_color=255):\n",
    "    \n",
    "    # Next we'll create a masked edges image using cv2.fillPoly()\n",
    "    mask = np.zeros_like(image)   \n",
    "\n",
    "    # This time we are defining a four sided polygon to mask\n",
    "    imshape = image.shape\n",
    "    xinset = 70\n",
    "    xclip = 50\n",
    "    yclip = 50\n",
    "    vertices = np.array([[(xinset,imshape[0]),(imshape[1]/2-xclip, imshape[0]/2+yclip), (imshape[1]/2+xclip, imshape[0]/2+yclip), (imshape[1]-xinset,imshape[0])]], dtype=np.int32)\n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    return cv2.bitwise_and(image, mask)\n",
    "\n",
    "\n",
    "# Define a function that applies Sobel x or y, \n",
    "# then takes an absolute value and applies a threshold.\n",
    "def abs_sobel_thresh(gray, orient='x', sobel_kernel=3, thresh=(0, 255)):\n",
    "    \n",
    "    # Apply the following steps to img\n",
    "    \n",
    "    # 2) Take the derivative in x or y given orient = 'x' or 'y'\n",
    "    if orient == 'x':\n",
    "        sobel = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    else:\n",
    "        sobel = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    \n",
    "    # 3) Take the absolute value of the derivative or gradient\n",
    "    abs_sobel = np.absolute(sobel)\n",
    "    \n",
    "    # 4) Scale to 8-bit (0 - 255) then convert to type = np.uint8\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    \n",
    "    # 5) Create a mask of 1's where the scaled gradient magnitude \n",
    "    #    is > thresh_min and < thresh_max\n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    binary_output[(scaled_sobel >= thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
    "    \n",
    "    # 6) Return this mask as your binary_output image\n",
    "    return binary_output\n",
    "\n",
    "\n",
    "# Define a function that applies Sobel x and y, \n",
    "# then computes the magnitude of the gradient\n",
    "# and applies a threshold\n",
    "def mag_thresh(gray, sobel_kernel=3, mag_thresh=(0, 255)):\n",
    "    \n",
    "    # Apply the following steps to img\n",
    "    # 2) Take the gradient in x and y separately\n",
    "    # sobelx = abs_sobel_thresh(img, 'x', mag_thresh[0], mag_thresh[1])\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    # sobely = abs_sobel_thresh(img, 'y', mag_thresh[0], mag_thresh[1])\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # 3) Calculate the magnitude \n",
    "    abs_sobelxy = np.sqrt(np.add(np.square(sobelx), np.square(sobely)))\n",
    "    # 4) Scale to 8-bit (0 - 255) and convert to type = np.uint8\n",
    "    scaled_sobel = np.uint8(255*abs_sobelxy/np.max(abs_sobelxy))\n",
    "    # 5) Create a binary mask where mag thresholds are met\n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    binary_output[(scaled_sobel >= mag_thresh[0]) & (scaled_sobel <= mag_thresh[1])] = 1\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    return binary_output\n",
    "\n",
    "\n",
    "# Define a function that applies Sobel x and y, \n",
    "# then computes the direction of the gradient\n",
    "# and applies a threshold.\n",
    "def dir_threshold(gray, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    \n",
    "    # # Apply the following steps to img\n",
    "    # 2) Take the gradient in x and y separately\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # 3) Take the absolute value of the x and y gradients\n",
    "    abs_sobelx = np.absolute(sobelx)\n",
    "    abs_sobely = np.absolute(sobely)\n",
    "    # 4) Use np.arctan2(abs_sobely, abs_sobelx) to calculate the direction of the gradient \n",
    "    graddir = np.arctan2(abs_sobely, abs_sobelx)\n",
    "    # 5) Create a binary mask where direction thresholds are met\n",
    "    binary_output = np.zeros_like(graddir)\n",
    "    binary_output[(graddir >= thresh[0]) & (graddir <= thresh[1])] = 1\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    return binary_output\n",
    "\n",
    "\n",
    "# Define a function that thresholds the S-channel of HLS\n",
    "# Use exclusive lower bound (>) and inclusive upper (<=)\n",
    "def hls_select_s(img, thresh=(0, 255)):\n",
    "    \n",
    "    # 1) Convert to HLS color space\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "    # 2) Apply a threshold to the S channel\n",
    "    S = hls[:,:,2]\n",
    "    binary_output = np.zeros_like(S)\n",
    "    binary_output[(S > thresh[0]) & (S <= thresh[1])] = 1\n",
    "    # 3) Return a binary image of threshold result\n",
    "    return binary_output\n",
    "\n",
    "\n",
    "# Choose a Sobel kernel size\n",
    "ksize = 3 # Choose a larger odd number to smooth gradient measurements\n",
    "    \n",
    "\n",
    "# Encapsulate a subset of the above transforms, after experimenting with various \n",
    "# combinations to discover what works best\n",
    "def apply_threshold_transforms(img, showImages=False, imgName=None):\n",
    "    \n",
    "    # Convert color image to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Convert to HLS color space\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "    H = hls[:,:,0]\n",
    "    L = hls[:,:,1]\n",
    "    S = hls[:,:,2]\n",
    "\n",
    "    # Apply each of the thresholding functions to gray\n",
    "    gradx = abs_sobel_thresh(gray, orient='x', sobel_kernel=ksize, thresh=(20, 100))\n",
    "    grady = abs_sobel_thresh(gray, orient='y', sobel_kernel=ksize, thresh=(20, 100))\n",
    "    mag_binary = mag_thresh(gray, sobel_kernel=ksize, mag_thresh=(100, 255))\n",
    "    dir_binary = dir_threshold(gray, sobel_kernel=ksize, thresh=(0, np.pi/2))\n",
    "        \n",
    "#     sxbinary = np.zeros_like(gray)\n",
    "#     sxbinary[((gradx == 1) & (grady == 1)) | ((mag_binary == 1) & (dir_binary == 1))] = 1\n",
    "    sxbinary = gradx\n",
    "        \n",
    "    # Apply a threshold to the S channel\n",
    "    s_binary = np.zeros_like(S)\n",
    "    s_binary[(S > 100) & (S <= 120)] = 1\n",
    "#     s_binary[(L > 100) & (L <= 255)] &= 1\n",
    "    s_binary[(H > 80) & (H <= 255)] &= 1\n",
    "        \n",
    "    # Stack each channel to view their individual contributions in green and blue respectively\n",
    "    # This returns a stack of the two binary images, whose components you can see as different colors\n",
    "#     stacked_binary = np.dstack(( np.zeros_like(gray), sxbinary, s_binary)) * 255\n",
    "\n",
    "    # Combine the two binary thresholds\n",
    "    binary_image = np.zeros_like(sxbinary)\n",
    "    binary_image[(s_binary == 1) | (sxbinary == 1)] = 1\n",
    "    \n",
    "    # Filter out the areas of the image where we don't expect to find\n",
    "    # lane lines, leaving only a trapezoid around the receding lane lines\n",
    "    binary_image = apply_trapezoid_mask(binary_image, 1)\n",
    "    \n",
    "    if imgName is not None:\n",
    "        # Draw the trapezoid on the visualization image\n",
    "        f, (ax1) = plt.subplots(1, 1, figsize=(20,10))\n",
    "        ax1.imshow(binary_image*255)\n",
    "        ax1.set_title('Threshold Transform', fontsize=30)\n",
    "        \n",
    "        # Write each undistorted image to the 'output_images' dir\n",
    "        cv2.imwrite(output_images_dir + 'threshold_' + imgName[16:], binary_image*255)\n",
    "        \n",
    "    \n",
    "    return binary_image\n",
    "\n",
    "def test_threshold():\n",
    "    \n",
    "    # Make a list of calibration images\n",
    "    undist_images_dir = \"./undist_images/\"\n",
    "\n",
    "    # Step through the list and undistort each image\n",
    "    for fname in sorted(glob.glob(os.path.join(undist_images_dir, '*.jpg'))):\n",
    "        dst = cv2.imread(fname)\n",
    "\n",
    "        apply_threshold_transforms(dst, showImages=False, imgName=fname)\n",
    "        \n",
    "        break\n",
    "        \n",
    "test_threshold()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the perspective transform\n",
    "\n",
    "Once we have a thresholded binary image that isolates the lane line information, I warp it into a \"birds-eye\" view for further processing.\n",
    "\n",
    "The values for providing the perspective transform were arrived at partially through a process of trial and error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Get M, the perspective transform for our camera.\n",
    "def calc_perspective_transforms(img=None, imgName=None):\n",
    "    \n",
    "    src_pts = np.float32([[570,468],  [717,468], [1106,720], [207,720]])\n",
    "    top_left = [320, 200]\n",
    "    top_right = [920, 200]\n",
    "    bottom_right = [920, 720]\n",
    "    bottom_left = [320,720] \n",
    "    dst_pts = np.float32([top_left,top_right,bottom_right, bottom_left])\n",
    "\n",
    "    if img is not None:\n",
    "        # Draw the trapezoid on the visualization image\n",
    "        pts = np.array([[570,468],  [717,468], [1106,720], [207,720]])\n",
    "        pts = pts.reshape((-1,1,2))\n",
    "        cv2.fillPoly(img,[pts],(0,255,255))\n",
    "        f, (ax1) = plt.subplots(1, 1, figsize=(20,10))\n",
    "        ax1.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        ax1.set_title('Perspective Transform Trapezoid', fontsize=30)\n",
    "        \n",
    "        # Write each undistorted image to the 'output_images' dir\n",
    "        cv2.imwrite(output_images_dir + 'warp_pts_' + imgName[16:], img)\n",
    "\n",
    "    \n",
    "    # Calculate M and Minv\n",
    "    M = cv2.getPerspectiveTransform(src_pts, dst_pts)\n",
    "    Minv = cv2.getPerspectiveTransform(dst_pts, src_pts)\n",
    "    \n",
    "    return M, Minv\n",
    "\n",
    "M, Minv = calc_perspective_transforms()\n",
    "\n",
    "def test_warp_pts():\n",
    "    \n",
    "    # Make a list of calibration images\n",
    "    undist_images_dir = \"./undist_images/\"\n",
    "\n",
    "    # Step through the list and undistort each image\n",
    "    for fname in sorted(glob.glob(os.path.join(undist_images_dir, '*.jpg'))):\n",
    "        dst = cv2.imread(fname)\n",
    "\n",
    "        calc_perspective_transforms(dst, fname)\n",
    "        \n",
    "        break\n",
    "        \n",
    "test_warp_pts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the curvature\n",
    "Derive the curvature, in meters\n",
    "Estimate the number of meters per pixel for both the x and y axes of the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_lane_curvature(leftx, lefty, rightx, righty):\n",
    "    \n",
    "    # Calculate curvature\n",
    "    y_eval = 719  # 720p video/image, so last (lowest on screen) y index is 719\n",
    "\n",
    "    # Define conversions in x and y from pixel space to meters\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "\n",
    "    # Fit new polynomials to x,y in meters\n",
    "    left_fit_cr = np.polyfit(lefty*ym_per_pix, leftx*xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(righty*ym_per_pix, rightx*xm_per_pix, 2)\n",
    "    \n",
    "    # Calculate the new radii of curvature, for both the Left and Right lane lines, in meters\n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "    \n",
    "    return left_curverad, right_curverad\n",
    "\n",
    "#Alternative, for use during the fast-fit\n",
    "def calc_lane_curvature2(left_lane_inds, right_lane_inds, nonzerox, nonzeroy):\n",
    "    \n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds]\n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    return calc_lane_curvature(leftx, lefty, rightx, righty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate vehicle offset\n",
    "Calculate whether the vehicle is to the Left or Right of the lane center,\n",
    "and by how much, in meters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_vehicle_offset(undist, xm_per_pix, left_fit, right_fit):\n",
    "    \n",
    "    # Calculate vehicle center offset in pixels\n",
    "    bottom_y = undist.shape[0] - 1\n",
    "    bottom_x_left = left_fit[0]*(bottom_y**2) + left_fit[1]*bottom_y + left_fit[2]\n",
    "    bottom_x_right = right_fit[0]*(bottom_y**2) + right_fit[1]*bottom_y + right_fit[2]\n",
    "    vehicle_offset_m = undist.shape[1]/2 - (bottom_x_left + bottom_x_right)/2\n",
    "\n",
    "    # Convert pixel offset to meters\n",
    "    vehicle_offset_m *= xm_per_pix\n",
    "\n",
    "    return vehicle_offset_m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply a perspective transform to rectify binary image (\"birds-eye view\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Return L and R Line objects\n",
    "def apply_perspective_transform(binary_warped, M, showImages=False, imgName=None):\n",
    "    \n",
    "    # Assuming you have created a warped binary image called \"binary_warped\"\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)\n",
    "    \n",
    "    # Create an output image to draw on and  visualize the result\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "    \n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]/2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "    # Set height of windows\n",
    "    window_height = np.int(binary_warped.shape[0]/nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated for each window\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 40\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        \n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_warped.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        \n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high),\n",
    "        (0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high),\n",
    "        (0,255,0), 2) \n",
    "        \n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        \n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        \n",
    "        # If we found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds] \n",
    "\n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "    out_img[lefty, leftx] = [255, 0, 0]\n",
    "    out_img[righty, rightx] = [0, 0, 255]\n",
    "    \n",
    "    if showImages:\n",
    "        plt.imshow(out_img)\n",
    "        plt.plot(left_fitx, ploty, color='yellow')\n",
    "        plt.plot(right_fitx, ploty, color='yellow')\n",
    "        plt.xlim(0, 1280)\n",
    "        plt.ylim(720, 0)\n",
    "        \n",
    "            \n",
    "    if imgName is not None:\n",
    "        # Write each undistorted image to the 'output_images' dir\n",
    "        cv2.imwrite(output_images_dir + 'perspective_' + imgName[16:], out_img)\n",
    "\n",
    "            \n",
    "    return left_fit, right_fit, leftx, lefty, rightx, righty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect lane pixels and fit to find the lane boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_warped_image(dst, M, showImages=False):\n",
    "        \n",
    "    warped_dst = cv2.warpPerspective(dst, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "    warped_orig = cv2.warpPerspective(img, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "\n",
    "    # Write the resulting image to the 'output_images' dir\n",
    "#     gray_image = cv2.cvtColor(warped_dst*255, cv2.COLOR_GRAY2BGR)\n",
    "#     cv2.imwrite(warped_images_dir + fname[16:], warped_dst)\n",
    "    \n",
    "    if showImages:\n",
    "        # Plot the result\n",
    "        f, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "        f.tight_layout()\n",
    "        ax1.imshow(cv2.cvtColor(warped_orig, cv2.COLOR_BGR2RGB))\n",
    "        ax1.set_title('Warped Image', fontsize=30)\n",
    "        ax2.imshow(warped_dst, cmap='gray')\n",
    "        ax2.set_title('Threshold Gradient', fontsize=30)\n",
    "        \n",
    "    return warped_dst\n",
    "\n",
    "import copy\n",
    "\n",
    "# Choose a Sobel kernel size\n",
    "ksize = 3 # Choose a larger odd number to smooth gradient measurements\n",
    "\n",
    "first = True\n",
    "\n",
    "# Step through the list and undistort each image\n",
    "for fname in sorted(glob.glob(os.path.join(undist_images_dir, '*.jpg'))):\n",
    "    img = cv2.imread(fname)\n",
    "\n",
    "    # Apply threshold transforms (color, sobel)\n",
    "    binary_image = apply_threshold_transforms(img)\n",
    "\n",
    "    # Get the warped image\n",
    "    warped_dst = get_warped_image(binary_image, M, showImages=True)\n",
    "    \n",
    "    # Apply the perspective transform and generate a coded image showing\n",
    "    # threshold detection, lane lines, and the boxes we used to detect \n",
    "    # key points in the lane lines\n",
    "    if first:\n",
    "        imgName = fname\n",
    "        first = False\n",
    "    else:\n",
    "        imgName = None\n",
    "    apply_perspective_transform(warped_dst, M, showImages=True, imgName=imgName)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def anno_vid_image(undist, left_fit, right_fit, Minv, left_curve, right_curve, vehicle_offset):\n",
    "\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, undist.shape[0]-1, undist.shape[0])\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "    # Create an image to draw the lines on\n",
    "    color_warp = np.zeros((img_size[1], img_size[0], 3), dtype='uint8')\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0, 255, 0))\n",
    "\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (undist.shape[1], undist.shape[0]))\n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(undist, 1, newwarp, 0.3, 0)\n",
    "\n",
    "    # Annotate lane curvature values and vehicle offset from center\n",
    "    avg_curve = (left_curve + right_curve)/2\n",
    "    label_str = 'Radius of curvature: %.1f m' % avg_curve\n",
    "    result = cv2.putText(result, label_str, (50, 50), 0, 1, (0,0,0), 2, cv2.LINE_AA)\n",
    "\n",
    "    if vehicle_offset < 0:\n",
    "        label_str = 'Vehicle is %.1f m left of center' % -vehicle_offset\n",
    "    else:\n",
    "        label_str = 'Vehicle is %.1f m right of center' % vehicle_offset\n",
    "\n",
    "    result = cv2.putText(result, label_str, (50, 80), 0, 1, (0,0,0), 2, cv2.LINE_AA)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### The Line class\n",
    "Define a class to capture the characteristics of each line detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Line():\n",
    "    def __init__(self, n):\n",
    "        \n",
    "        self.n = n\n",
    "\n",
    "        # Polynomial coefficients: x = A*y^2 + B*y + C\n",
    "        # Each of A, B, C is a \"list-queue\" with max length n\n",
    "        self.A = []\n",
    "        self.B = []\n",
    "        self.C = []\n",
    "        # Average of above\n",
    "        self.A_avg = 0.\n",
    "        self.B_avg = 0.\n",
    "        self.C_avg = 0.\n",
    "\n",
    "    def get_fit(self):\n",
    "        \n",
    "        return (self.A_avg, self.B_avg, self.C_avg)\n",
    "\n",
    "    def add_fit(self, fit_coeffs):\n",
    "\n",
    "        # Coefficient queue full?\n",
    "        q_full = len(self.A) >= self.n\n",
    "\n",
    "        # Append line fit coefficients\n",
    "        self.A.append(fit_coeffs[0])\n",
    "        self.B.append(fit_coeffs[1])\n",
    "        self.C.append(fit_coeffs[2])\n",
    "\n",
    "        # Pop from index 0 if full\n",
    "        if q_full:\n",
    "            _ = self.A.pop(0)\n",
    "            _ = self.B.pop(0)\n",
    "            _ = self.C.pop(0)\n",
    "\n",
    "        # Simple average of line coefficients\n",
    "        self.A_avg = np.mean(self.A)\n",
    "        self.B_avg = np.mean(self.B)\n",
    "        self.C_avg = np.mean(self.C)\n",
    "\n",
    "        return (self.A_avg, self.B_avg, self.C_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write lane lines to the project video\n",
    "For each frame in the video, apply all transforms and lane line detection, and save the resulting annotated frame to the annotated video file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pickle\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "# Global variables (for use by annotate_frame())\n",
    "with open('calibration.p', 'rb') as f:\n",
    "    save_dict = pickle.load(f)\n",
    "mtx = save_dict['mtx']\n",
    "dist = save_dict['dist']\n",
    "\n",
    "xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "\n",
    "window_size = 5  # how many frames for line smoothing\n",
    "left_line = Line(n=window_size)\n",
    "right_line = Line(n=window_size)\n",
    "detected = False  # did the fast line fit detect the lines?\n",
    "left_curverad, right_curverad = 0., 0.  # radius of curvature for left and right lanes\n",
    "left_lane_inds, right_lane_inds = None, None  # for calculating curvature\n",
    "\n",
    "# Given a previously fit line, quickly try to find the line based on previous lines\n",
    "def fast_fit(binary_warped, left_fit, right_fit):\n",
    "\n",
    "    # Assume you now have a new warped binary image\n",
    "    # from the next frame of video (also called \"binary_warped\")\n",
    "    # It's now much easier to find line pixels!\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    margin = 100\n",
    "    left_lane_inds = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] - margin)) & (nonzerox < (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] + margin)))\n",
    "    right_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] - margin)) & (nonzerox < (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] + margin)))\n",
    "\n",
    "    # Again, extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds]\n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    # If we don't find enough relevant points, return all None (this means error)\n",
    "    min_inds = 12\n",
    "    if lefty.shape[0] < min_inds or righty.shape[0] < min_inds:\n",
    "        return None\n",
    "\n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "    # Return a dict of relevant variables\n",
    "    ret = {}\n",
    "    ret['left_fit'] = left_fit\n",
    "    ret['right_fit'] = right_fit\n",
    "    ret['nonzerox'] = nonzerox\n",
    "    ret['nonzeroy'] = nonzeroy\n",
    "    ret['left_lane_inds'] = left_lane_inds\n",
    "    ret['right_lane_inds'] = right_lane_inds\n",
    "    \n",
    "    return ret\n",
    "\n",
    "# MoviePy video annotation will call this function\n",
    "def annotate_frame(img, showImages=False):\n",
    "    \n",
    "    global mtx, dist\n",
    "    global left_line, right_line, detected\n",
    "    global left_curverad, right_curverad, left_lane_inds, right_lane_inds\n",
    "\n",
    "    # Apply anti-distortion transform to the image\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "\n",
    "    # Apply threshold transforms (color, sobel)\n",
    "    binary_image = apply_threshold_transforms(undist)\n",
    "\n",
    "    # Get the warped image\n",
    "    warped_dst = get_warped_image(binary_image, M, showImages)\n",
    "    \n",
    "    # Perform polynomial fit\n",
    "    if not detected:\n",
    "        # Slow line fit\n",
    "        print('Frame was not detected')\n",
    "        \n",
    "        # Apply the perspective transform and generate a coded image showing\n",
    "        # threshold detection, lane lines, and the boxes we used to detect \n",
    "        # key points in the lane lines\n",
    "        left_fit, right_fit, leftx, lefty, rightx, righty = apply_perspective_transform(warped_dst, M, showImages)\n",
    "\n",
    "        # Get moving average of line fit coefficients\n",
    "        left_fit = left_line.add_fit(left_fit)\n",
    "        right_fit = right_line.add_fit(right_fit)\n",
    "\n",
    "        # Calculate the curvature for each line, as radii in meters\n",
    "        left_curverad, right_curverad = calc_lane_curvature(leftx, lefty, rightx, righty)\n",
    "\n",
    "        detected = True  # slow lne fit always detects the line\n",
    "\n",
    "    else:  # implies detected == True\n",
    "        # Fast line fit\n",
    "\n",
    "        left_fit = left_line.get_fit()\n",
    "        right_fit = right_line.get_fit()\n",
    "        ret = fast_fit(warped_dst, left_fit, right_fit)\n",
    "\n",
    "        # Only make updates if we detected lines in current frame\n",
    "        if ret is not None:\n",
    "            left_fit = ret['left_fit']\n",
    "            right_fit = ret['right_fit']\n",
    "            nonzerox = ret['nonzerox']\n",
    "            nonzeroy = ret['nonzeroy']\n",
    "            left_lane_inds = ret['left_lane_inds']\n",
    "            right_lane_inds = ret['right_lane_inds']\n",
    "\n",
    "            left_fit = left_line.add_fit(left_fit)\n",
    "            right_fit = right_line.add_fit(right_fit)\n",
    "            left_curverad, right_curverad = calc_lane_curvature2(left_lane_inds, right_lane_inds, nonzerox, nonzeroy)\n",
    "        else:\n",
    "            print('Fit was not detected')\n",
    "            detected = False\n",
    "\n",
    "            \n",
    "    vehicle_offset = calc_vehicle_offset(undist, xm_per_pix, left_fit, right_fit)\n",
    "\n",
    "    # Perform final visualization on top of original undistorted image\n",
    "    result = anno_vid_image(undist, left_fit, right_fit, Minv, left_curverad, right_curverad, vehicle_offset)\n",
    "\n",
    "    return result\n",
    "\n",
    "def annotate_test_frames(firstOnly=False, showImages=True):\n",
    "\n",
    "    # Make a list of calibration images\n",
    "    test_images_dir = \"./test_images/\"\n",
    "    images = glob.glob(test_images_dir + \"*.jpg\")\n",
    "\n",
    "    # Step through the list and undistort each image\n",
    "    for idx, fname in enumerate(images):\n",
    "        img = cv2.imread(fname)\n",
    "        \n",
    "        # Apply anti-distortion transform to the image\n",
    "        undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "\n",
    "        # Apply threshold transforms (color, sobel)\n",
    "        binary_image = apply_threshold_transforms(undist)\n",
    "        \n",
    "        # Get the warped image\n",
    "        warped_dst = get_warped_image(binary_image, M)\n",
    "\n",
    "        # Apply the perspective transform and generate a coded image showing\n",
    "        # threshold detection, lane lines, and the boxes we used to detect \n",
    "        # key points in the lane lines\n",
    "        left_fit, right_fit, leftx, lefty, rightx, righty = apply_perspective_transform(warped_dst, M, showImages=False)\n",
    "\n",
    "        # Calculate the curvature for each line, as radii in meters\n",
    "        left_curverad, right_curverad = calc_lane_curvature(leftx, lefty, rightx, righty)\n",
    "        vehicle_offset = calc_vehicle_offset(undist, xm_per_pix, left_fit, right_fit)\n",
    "\n",
    "        # Perform final visualization on top of original undistorted image\n",
    "        anno_img = anno_vid_image(undist, left_fit, right_fit, Minv, left_curverad, right_curverad, vehicle_offset)\n",
    "\n",
    "        if showImages:\n",
    "            # Visualize undistortion\n",
    "            f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "            ax1.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "            ax1.set_title('Original Image', fontsize=30)\n",
    "            ax2.imshow(cv2.cvtColor(anno_img, cv2.COLOR_BGR2RGB))\n",
    "            ax2.set_title('Annotated Undistorted Image', fontsize=30)\n",
    "\n",
    "        if firstOnly:\n",
    "            break\n",
    "\n",
    "def annotate_video(input_file, output_file):\n",
    "    \n",
    "    left_line = Line(n=window_size)\n",
    "    right_line = Line(n=window_size)\n",
    "    detected = False  # did the fast line fit detect the lines?\n",
    "    left_curverad, right_curverad = 0., 0.  # radius of curvature for left and right lanes\n",
    "    left_lane_inds, right_lane_inds = None, None  # for calculating curvature\n",
    "\n",
    "    video = VideoFileClip(input_file)\n",
    "    annotated_video = video.fl_image(annotate_frame)\n",
    "    annotated_video.write_videofile(output_file, audio=False)\n",
    "    \n",
    "# Annotate the test frames first\n",
    "# annotate_test_frames()\n",
    "\n",
    "# Annotate the video\n",
    "# annotate_video('project_video.mp4', 'project_out.mp4')\n",
    "\n",
    "# Annotate the video\n",
    "# annotate_video('challenge_video.mp4', 'challenge_out.mp4')\n",
    "\n",
    "# Annotate the video\n",
    "# annotate_video('harder_challenge_video.mp4', 'harder_challenge_out.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
